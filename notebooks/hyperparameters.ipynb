{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-19 11:57:17.887\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m14\u001b[0m - \u001b[1mPROJ_ROOT path is: G:\\Work\\DS\\dont-bet-on-sports\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from src.config import PROCESSED_DATA_DIR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "input_test_path: Path = PROCESSED_DATA_DIR / \"testset.csv\"\n",
    "input_train_path: Path = PROCESSED_DATA_DIR / \"trainset.csv\"\n",
    "\n",
    "df_test = pd.read_csv(str(input_test_path), index_col='id')\n",
    "df_train = pd.read_csv(str(input_train_path), index_col='id')\n",
    "\n",
    "X_train, y_train = df_train.drop(columns=['r_spread']), df_train['r_spread']\n",
    "X_test, y_test = df_test.drop(columns=['r_spread']), df_test['r_spread']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "Best Parameters: {'n_estimators': 950, 'min_weight_fraction_leaf': 0.125, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 30, 'ccp_alpha': 0.07777777777777778, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Initialize the RandomForestRegressor\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "param_distributions = {\n",
    "    'n_estimators': np.arange(100, 1000, 50),  # Number of trees (high range due to large search space)\n",
    "    'max_depth': [None, 10, 20, 30, 50, 100],  # Increasing depth to explore complex models\n",
    "    'min_samples_split': [2, 5, 10, 20],       # Control overfitting with more splits\n",
    "    'min_samples_leaf': [1, 2, 4, 8],           # Minimum samples per leaf\n",
    "    'bootstrap': [True, False],                 # Whether to use bootstrapping\n",
    "    'min_weight_fraction_leaf': np.linspace(0, 0.5, 5),  # Regularization parameter\n",
    "    'ccp_alpha': np.linspace(0, 0.1, 10)        # Complexity parameter for pruning\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV setup: sampling from 170 parameters efficiently\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=30,  # Sample only 30 combinations\n",
    "    cv=3,  # Use 3-fold cross-validation for faster results\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,  # Utilize all available CPU cores\n",
    "    scoring='neg_mean_absolute_error'\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV on the training data\n",
    "random_search.fit(df_train.drop(columns=['r_spread']), df_train['r_spread'])\n",
    "\n",
    "# Get the best parameters and model\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "rfr_best_model = random_search.best_estimator_\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "y_pred = rfr_best_model.predict(df_test.drop(columns=['r_spread']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFR Test MAE: 9.971237437377846\n"
     ]
    }
   ],
   "source": [
    "rf_mae = mean_absolute_error(df_test['r_spread'], y_pred)\n",
    "print(\"RFR Test MAE:\", rf_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\Work\\DS\\dont-bet-on-sports\\.venv\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'subsample': 0.8333333333333333, 'reg_lambda': 0.1, 'reg_alpha': 0.001, 'n_estimators': 200, 'learning_rate': 0.036000000000000004, 'gamma': 0.25, 'colsample_bytree': 0.5}\n",
      "GBT Test  MAE: 10.052160716606405\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the XGBoost Regressor\n",
    "xgb = XGBRegressor(objective='reg:absoluteerror', random_state=42, n_jobs=-1)\n",
    "\n",
    "# Define the hyperparameters to search over\n",
    "param_distributions = {\n",
    "    'n_estimators': np.arange(50, 1000, 50),  # Number of boosting rounds\n",
    "    'learning_rate': np.linspace(0.01, 0.4, 16),  # Shrinkage rate\n",
    "    'subsample': np.linspace(0.5, 1.0, 7),   # Fraction of samples per tree\n",
    "    'colsample_bytree': np.linspace(0.5, 1.0, 7),  # Fraction of features per tree\n",
    "    'gamma': np.linspace(0, 0.5, 5),         # Minimum loss reduction for further splits\n",
    "    'reg_alpha': np.logspace(-3, 1, 5),      # L1 regularization\n",
    "    'reg_lambda': np.logspace(-3, 1, 5)      # L2 regularization\n",
    "}\n",
    "\n",
    "# Setup RandomizedSearchCV to use MAE as the evaluation metric\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=30,  # Number of random parameter combinations to try\n",
    "    scoring='neg_mean_absolute_error',  # Use MAE as the evaluation metric\n",
    "    cv=3,  # 3-fold cross-validation for faster performance\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Use all CPU cores\n",
    ")\n",
    "\n",
    "# Fit the RandomizedSearchCV on the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "gbt_best_model = random_search.best_estimator_\n",
    "\n",
    "# Predict on the test data and evaluate using MAE\n",
    "y_pred = gbt_best_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"GBT Test  MAE: {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "Best Parameters: {'kernel': 'rbf', 'gamma': 0.001, 'epsilon': 0.12, 'C': 7.742636826811277}\n",
      "SVR Test MAE: 10.066851060626746\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svr = SVR()\n",
    "\n",
    "# Define the hyperparameters to search over\n",
    "param_distributions = {\n",
    "    'kernel':  ['rbf'],  # Kernel types\n",
    "    'C': np.logspace(-3, 2, 10),  # Regularization parameter\n",
    "    'epsilon': np.linspace(0.01, 1.0, 10),  # Epsilon in the epsilon-SVR model\n",
    "    'gamma': ['scale', 'auto'] + list(np.logspace(-3, 1, 5))  # Kernel coefficient\n",
    "}\n",
    "\n",
    "# Setup RandomizedSearchCV with MAE as the scoring metric\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=svr,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=30,  # Number of parameter combinations to try\n",
    "    scoring='neg_mean_absolute_error',  # Use MAE as the metric\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Use all available CPU cores\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV on the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "svr_best_model = random_search.best_estimator_\n",
    "\n",
    "# Predict on the test data and evaluate using MAE\n",
    "y_pred = svr_best_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"SVR Test MAE: {mae}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
